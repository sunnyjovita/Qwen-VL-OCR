{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Check the PDF Document Type\n",
    "# Image-based PDFs: Use Qwen-VL to extract text and visual data. \n",
    "# Text-based PDFs: Use fitz (PyMuPDF) or similar libraries to extract text directly.\n",
    "\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pathlib import Path\n",
    "\n",
    "def check_pdf_type_and_extract(pdf_path, output_dir=\"pdf_images\"):\n",
    "    \"\"\"\n",
    "    Check the type of PDF (text-based or image-based) and extract data accordingly.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "        output_dir (str): Directory to save images if the PDF is image-based.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted data (either text chunks or image paths).\n",
    "    \"\"\"\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Check if the PDF contains selectable text\n",
    "    is_text_based = False\n",
    "    for page in doc:\n",
    "        if page.get_text(\"text\").strip():  # Check if the page contains selectable text\n",
    "            is_text_based = True\n",
    "            break\n",
    "\n",
    "    #return \"text\" if is_text_based else \"image\"\n",
    "    \n",
    "    if is_text_based:\n",
    "        # Case 1: Text-Based PDF\n",
    "        print(\"✅ Detected text-based PDF. Extracting text...\")\n",
    "        return extract_text_with_page_numbers(doc)\n",
    "    else:\n",
    "        # Case 2: Image-Based PDF\n",
    "        print(\"✅ Detected image-based PDF. Converting pages to images...\")\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create the output directory\n",
    "        return convert_pdf_to_images(doc, output_dir)\n",
    "\n",
    "\n",
    "def extract_text_with_page_numbers(doc):\n",
    "    \"\"\"\n",
    "    Extract text from a text-based PDF with page numbers.\n",
    "    \n",
    "    Args:\n",
    "        doc (fitz.Document): Opened PDF document.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing page numbers and extracted text.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for page_num in range(len(doc)):\n",
    "        text = doc[page_num].get_text(\"text\")\n",
    "        if text.strip():\n",
    "            chunks.append({\n",
    "                \"page\": page_num + 1,  # Store page number (1-based index)\n",
    "                \"text\": text\n",
    "            })\n",
    "    return {\"type\": \"text\", \"data\": chunks}\n",
    "\n",
    "\n",
    "\n",
    "def convert_pdf_to_images(doc, output_dir):\n",
    "    \"\"\"\n",
    "    Convert each page of an image-based PDF to images.\n",
    "    \n",
    "    Args:\n",
    "        doc (fitz.Document): Opened PDF document.\n",
    "        output_dir (str): Directory to save the images.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the paths to the saved images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the PDF document\n",
    "    #doc = fitz.open(doc)\n",
    "\n",
    "    image_paths = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap()  # Convert the page to a pixmap (image)\n",
    "        image_path = os.path.join(output_dir, f\"page{page_num + 1}.png\")\n",
    "        pix.save(image_path)  # Save the image as a PNG file\n",
    "        image_paths.append(image_path)\n",
    "        print(f\"Saved: {image_path}\")\n",
    "    print(\"✅ PDF pages successfully converted to PNG!\")\n",
    "    return {\"type\": \"image\", \"data\": image_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pathlib import Path\n",
    "\n",
    "#Step 1: Convert PDF to images \n",
    "\n",
    "def check_pdf_type_and_convert_to_images(pdf_path, output_dir=\"pdf_images\"):\n",
    "    \"\"\"\n",
    "    Convert all pages of a PDF (text-based or image-based) into PNG images.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "        output_dir (str): Directory to save the generated PNG images.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the paths to the saved images.\n",
    "    \"\"\"\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"✅ Converting all PDF pages to PNG images...\")\n",
    "\n",
    "\n",
    "    base_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    # Convert each page to an image\n",
    "    image_paths = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap()  # Convert the page to a pixmap (image)\n",
    "        image_path = os.path.join(output_dir, f\"{base_filename}_page{page_num + 1}.png\")\n",
    "        #image_path = f\"{base_filename}_page{page_num + 1}.png\"\n",
    "\n",
    "        pix.save(image_path)  # Save the image as a PNG file\n",
    "        image_paths.append(image_path)\n",
    "        print(f\"Saved: {image_path}\")\n",
    "    \n",
    "    print(\"✅ All PDF pages successfully converted to PNG!\")\n",
    "    return {\"type\": \"image\", \"data\": image_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converting all PDF pages to PNG images...\n",
      "Saved: pdf_images/BC_file_page1.png\n",
      "Saved: pdf_images/BC_file_page2.png\n",
      "Saved: pdf_images/BC_file_page3.png\n",
      "Saved: pdf_images/BC_file_page4.png\n",
      "Saved: pdf_images/BC_file_page5.png\n",
      "Saved: pdf_images/BC_file_page6.png\n",
      "Saved: pdf_images/BC_file_page7.png\n",
      "✅ All PDF pages successfully converted to PNG!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'image',\n",
       " 'data': ['pdf_images/BC_file_page1.png',\n",
       "  'pdf_images/BC_file_page2.png',\n",
       "  'pdf_images/BC_file_page3.png',\n",
       "  'pdf_images/BC_file_page4.png',\n",
       "  'pdf_images/BC_file_page5.png',\n",
       "  'pdf_images/BC_file_page6.png',\n",
       "  'pdf_images/BC_file_page7.png']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input PDF path\n",
    "pdf_path = \"/Users/sunnyjovita/Desktop/Puninar/pdf_raw/BC_file.pdf\"\n",
    "\n",
    "# Output directory for images (if needed)\n",
    "output_dir = \"pdf_images\"\n",
    "\n",
    "# Check PDF type and extract data\n",
    "check_pdf_type_and_convert_to_images(pdf_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 Extracting text using Qwen VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "Strictly extract solely the text in detailed within the document in json format\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "\n",
    "\n",
    "# Role\n",
    "You are a meticulous document processing expert, skilled in extracting and organizing structured information from unstructured documents. Your role is to identify sections within a document, extract their content, and format the output as specified.\n",
    "\n",
    "## Skills\n",
    "### Skill 1: Section Identification\n",
    "- Identify all sections within the provided document.\n",
    "- Extract the names of the sections for use in the output.\n",
    "\n",
    "### Skill 2: Content Extraction\n",
    "- Extract all information contained within each identified section in detail.\n",
    "- Ensure that the extracted content is complete and unmodified.\n",
    "\n",
    "### Skill 3: JSON Formatting\n",
    "- Format the extracted section names and their corresponding content into a JSON structure.\n",
    "- Ensure the output strictly adheres to the specified JSON format without any additional explanation or modification.\n",
    "\n",
    "## Limitations\n",
    "- Only process the sections and content present in the document; do not add, remove, or modify any information.\n",
    "- Output must be in JSON format as specified, with no additional text or explanations.\n",
    "- If the document structure is unclear or ambiguous, make reasonable assumptions but ensure consistency in extraction.\n",
    "\n",
    "## Output Format\n",
    "json\n",
    "{\n",
    "    \"&lt;section&gt;\": \"&lt;information inside the section&gt;\",\n",
    "    \"&lt;section2&gt;\": \"&lt;information inside the section2&gt;\",\n",
    "    ...\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"\"\"You are a helpful assistant. \n",
    "\n",
    "Read all the text in the image. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: BC_file_page1.png\n",
      "Processing: BC_file_page3.png\n",
      "Processing: BC_file_page2.png\n",
      "Processing: BC_file_page6.png\n",
      "Processing: BC_file_page7.png\n",
      "Processing: BC_file_page5.png\n",
      "Processing: BC_file_page4.png\n",
      "Extraction completed! JSON saved at /Users/sunnyjovita/Desktop/Puninar/extracted_datafromquery1.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "# Function to encode an image file into base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Function to get response from the API for a single image\n",
    "def get_response(image_path):\n",
    "    base64_image = encode_image(image_path)\n",
    "    client = OpenAI(\n",
    "        api_key=\"put your apikey here\",\n",
    "        base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-vl-plus\",\n",
    "        messages=[\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"{query}\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "              ]\n",
    "            }\n",
    "          ],\n",
    "          stream=False\n",
    "        )\n",
    "    \n",
    "    return json.loads(completion.model_dump_json())\n",
    "\n",
    "def process_images_in_folder(folder_path, output_json_path):\n",
    "    extracted_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing: {filename}\")\n",
    "            \n",
    "            try:\n",
    "                # Get raw response\n",
    "                response = get_response(image_path)\n",
    "                raw_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                \n",
    "                # Step 1: Clean markdown and prepare JSON\n",
    "                cleaned_json = raw_text.replace('```json', '').replace('```', '').strip()\n",
    "                \n",
    "                # Step 2: Process lines to add missing keys\n",
    "                lines = cleaned_json.split('\\n')\n",
    "                processed_lines = []\n",
    "                unstructured_counter = 0\n",
    "\n",
    "                for line in lines:\n",
    "                    stripped = line.strip()\n",
    "                    # Detect lines that start with a value but no key\n",
    "                    if stripped.startswith('\"') and ':' not in stripped:\n",
    "                        # Add default key with counter\n",
    "                        new_line = f'  \"unstructured_{unstructured_counter}\": {stripped},'\n",
    "                        processed_lines.append(new_line)\n",
    "                        unstructured_counter += 1\n",
    "                    else:\n",
    "                        processed_lines.append(line)\n",
    "\n",
    "                # Rebuild JSON and fix trailing commas\n",
    "                cleaned_json = '\\n'.join(processed_lines)\n",
    "                cleaned_json = re.sub(r',\\s*([}\\]])', r'\\1', cleaned_json)\n",
    "                \n",
    "                # Step 3: Validate and parse JSON\n",
    "                try:\n",
    "                    dict_output = json.loads(cleaned_json)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"  JSON structure error in {filename}: {e}\")\n",
    "                    print(\"  Attempting to save partial data...\")\n",
    "                    dict_output = {\"error\": str(e), \"raw_content\": raw_text}\n",
    "                \n",
    "                # Store results with filename as key\n",
    "                extracted_data[filename] = dict_output\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {filename}: {e}\")\n",
    "                extracted_data[filename] = {\"error\": str(e)}\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(extracted_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Set folder path and output JSON file path\n",
    "image_folder = \"/Users/sunnyjovita/Desktop/Puninar/pdf_images\"\n",
    "output_json = \"/Users/sunnyjovita/Desktop/Puninar/extracted_datafromquery1.json\"\n",
    "\n",
    "# Process images and save JSON\n",
    "process_images_in_folder(image_folder, output_json)\n",
    "print(f\"Extraction completed! JSON saved at {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
